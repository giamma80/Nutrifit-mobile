# üìò Guida Ottimizzazione Meal Photo Analyzer

**Versione:** 1.0  
**Target:** Sviluppatore Backend  
**Contesto:** ~100 utenti, ~2000 analisi/giorno, OpenAI GPT-4o-mini  
**Obiettivo:** Clean refactor per ridurre costi, latenza e migliorare manutenibilit√†

---

## üéØ Problema Principale

Il codice attuale genera un **prompt monolitico** (400+ token) inline ad ogni chiamata, senza sfruttare il **prompt caching** di OpenAI.

### Impatto Negativo
- ‚ùå Spreco di 400 token/chiamata (no caching)
- ‚ùå Latenza alta (~2500ms)
- ‚ùå Parsing JSON manuale fragile
- ‚ùå Calcoli temporanei inutili
- ‚ùå Codice difficile da manutenere

---

## ‚úÖ Soluzione: 3 Pilastri Fondamentali

### 1. **System Prompt Fisso + User Message Variabile**
**Perch√©:** OpenAI cacha automaticamente il system prompt (50% sconto, -20-30% latenza)

### 2. **Structured Output + Pydantic**
**Perch√©:** Elimina parsing manuale fragile, garantisce validazione type-safe

### 3. **Logging Strutturato**
**Perch√©:** Monitoring real-time, debugging semplificato, metriche business

---

## üö´ ANTIPATTERN da Evitare

### ‚ùå Antipattern #1: Prompt Monolitico Inline

```python
# ‚ùå SBAGLIATO - Genera tutto inline ogni volta
def generate_prompt_v3(*, locale: str = "it") -> str:
    return (
        "COMPITO: Analizza immagine..."
        "REGOLE: 1. dish_title..."
        "ESEMPI: eggs, chicken..."
        # 400+ token ripetuti OGNI chiamata!
    )

# Uso
prompt = generate_prompt_v3()  # Genera stringa gigante
messages = [{"role": "user", "content": prompt}]
```

**Perch√© √® male:**
- üî¥ 400 token sprecati ogni chiamata
- üî¥ Nessun caching (ogni volta full price)
- üî¥ Impossibile ottimizzare
- üî¥ Modifica prompt = trova tutte le chiamate

---

### ‚ùå Antipattern #2: Parsing JSON Manuale

```python
# ‚ùå SBAGLIATO - Parsing fragile
def _safe_json_extract(text: str) -> Dict:
    first = text.find("{")
    last = text.rfind("}")
    snippet = text[first:last+1]
    obj = json.loads(snippet)  # Pu√≤ fallire con markdown/code fence
    return obj
```

**Perch√© √® male:**
- üî¥ Fallisce con markdown (` ```json ... ``` `)
- üî¥ Fallisce con code fence
- üî¥ Fallisce con testo extra
- üî¥ Nessun type checking
- üî¥ Errori difficili da debuggare

---

### ‚ùå Antipattern #3: Calcoli Temporanei Inutili

```python
# ‚ùå SBAGLIATO - Calcoli che vengono sovrascritti
density, src_density = _resolve_density(label)
calories = int(density * q_final / 100.0)

# Poi questi valori vengono SOVRASCRITTI da NutrientEnrichmentService!
```

**Perch√© √® male:**
- üî¥ Spreco CPU
- üî¥ Pu√≤ generare dati inconsistenti
- üî¥ Confonde il flusso logico

---

### ‚ùå Antipattern #4: Dati Variabili nel System Prompt

```python
# ‚ùå SBAGLIATO - Cache invalidato ogni volta!
system = f"Analizza per utente {user_id} alle ore {timestamp}..."
messages = [{"role": "system", "content": system}]
```

**Perch√© √® male:**
- üî¥ Cache invalidato ad ogni chiamata (cambia sempre)
- üî¥ System prompt dovrebbe essere COSTANTE

---

### ‚ùå Antipattern #5: Tutto in User Message

```python
# ‚ùå SBAGLIATO - Tutto mischiato
messages = [
    {
        "role": "user",
        "content": ISTRUZIONI_FISSE + dati_variabili + immagine
    }
]
```

**Perch√© √® male:**
- üî¥ Nessun caching possibile
- üî¥ Confonde responsabilit√† (istruzioni vs dati)

---

## ‚úÖ PATTERN da Seguire

### ‚úÖ Pattern #1: System Fisso + User Variabile

```python
# ‚úÖ CORRETTO - System prompt come COSTANTE
MEAL_ANALYSIS_SYSTEM_PROMPT = """
Sei un nutrizionista esperto nell'analisi visiva di pasti.

COMPITO PRINCIPALE:
Analizza foto di cibo e identifica ingredienti con quantit√† stimate.

METODOLOGIA:
1. Identifica il piatto completo se riconoscibile (es: "spaghetti alla carbonara")
2. Se non riconosci la ricetta, identifica i singoli ingredienti principali
3. Stima le quantit√† in grammi usando riferimenti visivi standard
4. Assegna livello di confidence basato su chiarezza immagine

OUTPUT FORMATO (JSON):
{
  "dish_title": "nome piatto in italiano",
  "items": [
    {
      "label": "nome inglese USDA",
      "display_name": "nome italiano",
      "quantity": {"value": 100, "unit": "g"},
      "confidence": 0.9
    }
  ]
}

REGOLE CRITICHE:
1. dish_title: nome del piatto in italiano per l'utente
2. label: SEMPRE inglese, usa nomenclatura USDA standard
   - Uova: "eggs" (sempre plurale!), "egg white", "egg yolk"
   - Pollo: "chicken", "chicken breast", "chicken thigh"
   - Verdure: "tomatoes", "spinach", "broccoli", "potatoes"
3. display_name: nome italiano dell'ingrediente per interfaccia utente
4. Massimo 5 ingredienti principali per semplicit√†
5. confidence: valore 0.0-1.0 dove 0.7+ = alta certezza
6. quantity.unit: "g" per grammi, "piece" per pezzi interi

STIMA QUANTIT√Ä (riferimenti):
- Piatto normale: 23-25cm diametro
- Porzione pasta: 80-120g cruda, 200-300g cotta
- Bistecca: 150-250g
- Petto pollo: 150-200g
- Verdure: 80-150g

CONFIDENCE GUIDELINES:
- 0.9-1.0: Alimento chiaramente visibile, porzione ben definita
- 0.7-0.8: Alimento riconoscibile, stima ragionevole
- 0.5-0.6: Alimento probabile ma parzialmente nascosto
- <0.3: Non usare, scartare l'item

Se nessun cibo riconoscibile: {"dish_title":"","items":[]}

Rispondi SOLO con JSON valido UTF-8. NESSUN testo extra, markdown, o code fence.
"""
# ‚Üë Questo deve essere >1024 token! Aggiungi altri esempi se necessario.

# ‚úÖ User message minimal - solo dati specifici
def analyze(photo_url: str, dish_hint: str = None):
    user_text = f"Suggerimento: {dish_hint}\nAnalizza:" if dish_hint else "Analizza:"
    
    messages = [
        {
            "role": "system",           # ‚Üê FISSO, cachato
            "content": MEAL_ANALYSIS_SYSTEM_PROMPT
        },
        {
            "role": "user",             # ‚Üê VARIABILE, sempre diverso
            "content": [
                {"type": "text", "text": user_text},
                {"type": "image_url", "image_url": {"url": photo_url}}
            ]
        }
    ]
```

**Perch√© √® bene:**
- ‚úÖ System prompt cachato (50% sconto dopo prima chiamata)
- ‚úÖ Con 1.4 chiamate/minuto ‚Üí cache hit rate >90%
- ‚úÖ User message minimal (~20 token vs 400)
- ‚úÖ Separazione responsabilit√† chiara

---

### ‚úÖ Pattern #2: Structured Output + Pydantic

```python
# ‚úÖ CORRETTO - Pydantic models
from pydantic import BaseModel, Field
from typing import List, Literal

class FoodQuantity(BaseModel):
    value: float = Field(gt=0, le=2000)
    unit: Literal["g", "piece"]

class FoodItem(BaseModel):
    label: str
    display_name: str
    quantity: FoodQuantity
    confidence: float = Field(ge=0.0, le=1.0)

class MealAnalysisResponse(BaseModel):
    dish_title: str
    items: List[FoodItem] = Field(max_length=5)

# ‚úÖ API call con structured output
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,
    response_format={"type": "json_object"}  # ‚Üê Force JSON
)

# ‚úÖ Parsing type-safe
result = MealAnalysisResponse.model_validate_json(
    response.choices[0].message.content
)
# result.items[0].label  ‚Üê Autocomplete, type-safe!
```

**Perch√© √® bene:**
- ‚úÖ OpenAI garantisce JSON valido
- ‚úÖ Pydantic valida automaticamente
- ‚úÖ Type safety (no errori runtime)
- ‚úÖ Autocomplete nell'IDE
- ‚úÖ 0% parsing errors

---

### ‚úÖ Pattern #3: Logging Strutturato JSON

```python
# ‚úÖ CORRETTO - Log strutturato
import logging
import json

logger = logging.getLogger("meal_analyzer")

def log_cache_metrics(cached_tokens: int, prompt_tokens: int):
    cache_rate = cached_tokens / prompt_tokens if prompt_tokens > 0 else 0
    
    logger.info(json.dumps({
        "event": "cache_metrics",
        "cached_tokens": cached_tokens,
        "prompt_tokens": prompt_tokens,
        "cache_hit": cached_tokens > 0,
        "cache_hit_rate": f"{cache_rate:.2%}",
        "savings_usd": cached_tokens * 0.075 / 1_000_000
    }))

# Analisi log facile:
# cat logs.json | jq -r 'select(.event=="cache_metrics") | .cache_hit_rate'
```

**Perch√© √® bene:**
- ‚úÖ Facilmente parsabile (jq, grep)
- ‚úÖ Dashboard automatiche
- ‚úÖ Debugging semplificato
- ‚úÖ Metriche business real-time

---

### ‚úÖ Pattern #4: Separazione Responsabilit√†

```python
# ‚úÖ CORRETTO - File separati

# config.py - Solo configurazione
SYSTEM_PROMPT = "..."
OPENAI_CONFIG = {"model": "gpt-4o-mini", ...}

# schemas.py - Solo models Pydantic
class MealAnalysisResponse(BaseModel): ...

# analyzer.py - Solo logica business
class MealPhotoAnalyzer:
    def analyze(self, photo_url, user_id): ...

# logger.py - Solo logging
class AnalysisLogger:
    def log_cache_metrics(...): ...
```

**Perch√© √® bene:**
- ‚úÖ Single Responsibility Principle
- ‚úÖ Facile testare
- ‚úÖ Facile manutenere
- ‚úÖ Chiaro dove modificare cosa

---

### ‚úÖ Pattern #5: Validazione sul Bordo

```python
# ‚úÖ CORRETTO - Valida appena ricevi dati
class FoodItem(BaseModel):
    confidence: float = Field(ge=0.0, le=1.0)
    
    @field_validator('confidence')
    @classmethod
    def reject_low_confidence(cls, v: float) -> float:
        if v < 0.3:
            raise ValueError("Confidence troppo bassa")
        return v
    
    @field_validator('label')
    @classmethod
    def normalize_label(cls, v: str) -> str:
        return v.lower().strip()
```

**Perch√© √® bene:**
- ‚úÖ Fail fast (errori immediati)
- ‚úÖ Dati sempre validi nel sistema
- ‚úÖ Normalizzazione automatica

---

## üìã Checklist Pre-Implementazione

### System Prompt
- [ ] System prompt √® una **COSTANTE** nel file config?
- [ ] System prompt √® **>1024 token**? (verifica con tiktoken)
- [ ] System prompt contiene **SOLO istruzioni fisse** (no user_id, timestamp)?
- [ ] User message √® **minimal** (<50 token)?

### Structured Output
- [ ] Uso `response_format={"type": "json_object"}`?
- [ ] Ho creato **Pydantic models** per la response?
- [ ] Ho **eliminato** `_safe_json_extract()`?
- [ ] Ho **eliminato** `parse_and_validate_v3()`?

### Code Quality
- [ ] Ho **eliminato** calcoli temporanei (density, calories)?
- [ ] Ho **separato** file per responsabilit√†?
- [ ] Ho **logging JSON** strutturato?
- [ ] Ho **eliminato** tutto il codice legacy?

### Testing
- [ ] Cache hit dopo 2+ chiamate ravvicinate?
- [ ] `cached_tokens > 0` nei log?
- [ ] Parsing **mai fallisce**?
- [ ] Schema GraphQL **invariato**?

---

## üéØ Regole d'Oro (Da Stampare e Appendere)

### ‚ö° Rule #1: System = Fisso, User = Variabile
```
System prompt = Istruzioni, regole, esempi (COSTANTE)
User message  = Dati specifici della richiesta (VARIABILE)
```

### üìè Rule #2: System Prompt > 1024 Token
```
< 1024 token = NO caching
> 1024 token = Caching attivo (50% sconto)
```

### üõ°Ô∏è Rule #3: Structured Output Always
```
No parsing manuale = No errori
Pydantic + response_format = Type safety garantita
```

### üìä Rule #4: Log Tutto (Structured)
```
JSON logging = Metriche facili
event + context = Debug immediato
```

### üóëÔ∏è Rule #5: Elimina, Non Commentare
```
Codice legacy = Elimina completamente
No // TODO, no commenti "old way"
Clean refactor = Tabula rasa
```

---

## üìä Metriche di Successo

### KPI Target (30 giorni)

| Metrica | Prima | Target | Come Misurare |
|---------|-------|--------|---------------|
| **Cache hit rate** | 0% | >85% | `cached_tokens > 0` |
| **Latenza media** | ~2500ms | <1800ms | `duration_ms` in log |
| **Parsing errors** | ~5/giorno | 0/giorno | Exception log count |
| **Costo/analisi** | $0.00015 | $0.00013 | Token usage √ó price |

### Come Monitorare

```bash
# Cache hit rate giornaliero
cat logs.json | jq -r 'select(.event=="cache_metrics") | .cache_hit' | \
  awk '{sum+=$1; n++} END {print sum/n*100"%"}'

# Latenza media
cat logs.json | jq -r 'select(.event=="analysis_complete") | .duration_ms' | \
  awk '{sum+=$1; n++} END {print sum/n"ms"}'

# Parsing errors
cat logs.json | jq -r 'select(.event=="analysis_error")' | wc -l
```

---

## üöÄ Implementazione Minima Funzionante

### Step 1: Config (5 minuti)
```python
# config.py
MEAL_ANALYSIS_SYSTEM_PROMPT = """
[Il tuo prompt completo qui - assicurati >1024 token]
"""
```

### Step 2: Schema (10 minuti)
```python
# schemas.py
from pydantic import BaseModel, Field
from typing import List

class FoodItem(BaseModel):
    label: str
    display_name: str
    confidence: float = Field(ge=0, le=1)

class MealAnalysisResponse(BaseModel):
    dish_title: str
    items: List[FoodItem]
```

### Step 3: Analyzer (30 minuti)
```python
# analyzer.py
from openai import OpenAI
from .config import MEAL_ANALYSIS_SYSTEM_PROMPT
from .schemas import MealAnalysisResponse

class MealPhotoAnalyzer:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)
    
    def analyze(self, photo_url: str, hint: str = None):
        # User message minimal
        user_text = f"Hint: {hint}\nAnalizza:" if hint else "Analizza:"
        
        # API call
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": MEAL_ANALYSIS_SYSTEM_PROMPT},
                {"role": "user", "content": [
                    {"type": "text", "text": user_text},
                    {"type": "image_url", "image_url": {"url": photo_url}}
                ]}
            ],
            response_format={"type": "json_object"}
        )
        
        # Parse type-safe
        return MealAnalysisResponse.model_validate_json(
            response.choices[0].message.content
        )
```

### Step 4: Integration (15 minuti)
```python
# Nel tuo resolver GraphQL - INTERFACE IDENTICA
analyzer = MealPhotoAnalyzer(api_key=settings.OPENAI_API_KEY)

async def resolve_analyze_meal_photo(parent, info, input):
    # Chiama nuovo analyzer
    result = analyzer.analyze(
        photo_url=input.photo_url,
        hint=input.dish_hint
    )
    
    # Converti in GraphQL type (come prima)
    items = [...]  # Enrichment + conversione
    return MealPhotoAnalysis(...)  # Schema invariato
```

---

## üí∞ ROI Atteso

**Con 2000 analisi/giorno:**

| Beneficio | Valore Annuale |
|-----------|----------------|
| Riduzione costi API | ~$14/anno |
| Riduzione tempo debug | ~$3,000/anno |
| Riduzione downtime | ~$500/anno |
| **Totale** | **~$3,514/anno** |

**Investimento:** 1 settimana dev (~$400)  
**ROI:** **8.8x** nel primo anno

---

## üèóÔ∏è Struttura File Consigliata

```
meal_photo/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ config.py           # System prompt + configurazione
‚îú‚îÄ‚îÄ schemas.py          # Pydantic models
‚îú‚îÄ‚îÄ analyzer.py         # Servizio principale
‚îú‚îÄ‚îÄ logger.py           # Logging strutturato
‚îî‚îÄ‚îÄ exceptions.py       # Custom exceptions
```

**Cosa Eliminare Completamente:**
- ‚ùå `generate_prompt()`, `generate_prompt_v2()`, `generate_prompt_v3()`
- ‚ùå `_safe_json_extract()`
- ‚ùå `parse_and_validate()`, `parse_and_validate_v3()`
- ‚ùå `_resolve_density()` (calcoli temporanei)
- ‚ùå Classe `ParseError`
- ‚ùå Classe `ParseStats` (sostituita da metrics in logging)

**Cosa Mantenere:**
- ‚úÖ Dataclasses di types (`MealPhotoAnalysisRecord`, etc)
- ‚úÖ GraphQL types (invariati)

---

## üß™ Strategia Testing

### Unit Tests
```python
def test_analyzer_cache_hit():
    analyzer = MealPhotoAnalyzer(api_key=TEST_KEY)
    
    # Prima chiamata
    result1 = analyzer.analyze(PHOTO_URL, "pasta")
    
    # Seconda chiamata (entro 5 min)
    result2 = analyzer.analyze(PHOTO_URL_2, "pollo")
    
    # Verifica cache metrics
    assert result2.metrics["cache_hit"] == True
    assert result2.metrics["cached_tokens"] > 1000
```

### Integration Tests
```python
async def test_graphql_schema_unchanged():
    # Query GraphQL
    query = """
    mutation {
      analyzeMealPhoto(input: {photoUrl: "...", userId: "..."}) {
        id
        dishName
        items { label displayName confidence }
      }
    }
    """
    
    result = await execute_graphql(query)
    
    # Schema deve essere identico
    assert "id" in result["analyzeMealPhoto"]
    assert "dishName" in result["analyzeMealPhoto"]
```

---

## ‚ùì FAQ per lo Sviluppatore

### Q: Devo riscrivere tutto?
**A:** No. Mantieni GraphQL schema identico. Riscrivi solo internals (analyzer, parser).

### Q: Cosa faccio del codice vecchio?
**A:** Eliminalo completamente. No commenti, no `_old.py`. Clean slate.

### Q: E se rompo qualcosa?
**A:** Testing strategy:
1. Testa analyzer standalone (unit test)
2. Testa con GraphQL (integration test)
3. Deploy graduale (10% ‚Üí 100%)

### Q: Come verifico che il cache funzioni?
**A:** Fai 2 chiamate ravvicinate (entro 5 minuti), controlla nei log che `cached_tokens > 0` nella seconda.

### Q: Quanto tempo richiede?
**A:** ~40 ore (1 settimana lavorativa):
- 8h: Setup + config
- 16h: Analyzer + schema
- 8h: Integration
- 8h: Testing + deploy

### Q: Devo cambiare il database?
**A:** No. Solo la logica di analisi cambia. Storage rimane identico.

### Q: E se il prompt √® <1024 token?
**A:** Aggiungi pi√π esempi, edge cases, spiegazioni dettagliate finch√© non superi 1024 token.

---

## üìö Verifica Token del System Prompt

```python
# Script per verificare token count
import tiktoken

SYSTEM_PROMPT = """[Il tuo prompt]"""

enc = tiktoken.encoding_for_model("gpt-4o-mini")
tokens = enc.encode(SYSTEM_PROMPT)

print(f"Token count: {len(tokens)}")
print(f"Caching: {'‚úÖ ATTIVO' if len(tokens) >= 1024 else '‚ùå DISATTIVATO'}")

if len(tokens) < 1024:
    print(f"‚ö†Ô∏è Aggiungi {1024 - len(tokens)} token per attivare cache!")
```

---

## üéì Risorse Essenziali

1. **OpenAI Prompt Caching**: https://platform.openai.com/docs/guides/prompt-caching
2. **Pydantic Docs**: https://docs.pydantic.dev/
3. **Structured Outputs**: https://platform.openai.com/docs/guides/structured-outputs
4. **Tiktoken (count tokens)**: https://github.com/openai/tiktoken

---

## üö® Red Flags (Quando Qualcosa va Male)

### üî¥ Cache hit rate < 50%
**Cause possibili:**
- System prompt contiene dati variabili
- Chiamate troppo distanziate (>10 min)
- System prompt < 1024 token

**Fix:** Verifica che system prompt sia COSTANTE e >1024 token

### üî¥ Parsing errors frequenti
**Cause possibili:**
- Non usi `response_format={"type": "json_object"}`
- Parsing manuale ancora presente
- Pydantic models non corrispondono a output

**Fix:** Verifica structured output e Pydantic validation

### üî¥ Latenza non migliora
**Cause possibili:**
- Cache non attivo
- Bottleneck in enrichment USDA
- Network issues

**Fix:** Profila con logging, identifica bottleneck

---

## ‚úÖ Checklist Finale

**Prima di iniziare:**
- [ ] Ho letto questo documento completamente
- [ ] Ho capito perch√© separare system/user
- [ ] Ho capito perch√© structured output
- [ ] Ho chiaro che GraphQL non cambia

**Durante lo sviluppo:**
- [ ] System prompt >1024 token verificato
- [ ] Pydantic models creati e validati
- [ ] Logging JSON implementato
- [ ] Codice legacy eliminato (non commentato)
- [ ] Unit test passano

**Prima del deploy:**
- [ ] Cache hit verificato (2+ chiamate)
- [ ] Latenza misurata (target <1800ms)
- [ ] GraphQL response identica
- [ ] Monitoring attivo
- [ ] Rollback plan pronto

---

## üìÖ Timeline Suggerita

### Giorno 1-2: Setup Base
- Crea nuova struttura file
- Implementa config.py con system prompt >1024 token
- Crea Pydantic models in schemas.py
- Setup logging strutturato

### Giorno 3-4: Core Implementation
- Implementa MealPhotoAnalyzer pulito
- Testa analisi singola con caching
- Verifica metrics logging

### Giorno 5: Integration
- Integra con resolver GraphQL
- Mantieni interfaccia identica
- Test end-to-end

### Giorno 6-7: Testing & Deploy
- Test con diverse foto
- Verifica cache hit rate
- Deploy graduale (10% ‚Üí 50% ‚Üí 100%)
- Monitora metriche

---

## üéØ Success Criteria

**Considerare il refactor SUCCESSO se:**
- ‚úÖ Cache hit rate >85% dopo 48h
- ‚úÖ Latenza media <1800ms
- ‚úÖ 0 parsing errors in 1 settimana
- ‚úÖ GraphQL schema invariato
- ‚úÖ Nessuna regressione funzionale
- ‚úÖ Monitoring attivo e funzionante

---

**Ultima Riga di Difesa:**

> Se il system prompt contiene `user_id`, `timestamp`, o qualsiasi dato che cambia tra chiamate ‚Üí **SBAGLIATO**.  
> System = COSTANTE. User = VARIABILE.

---

**Fine documento.**  
**Salva come `MEAL_PHOTO_REFACTOR.md` e inizia lo sviluppo.** üöÄ

---

## üìû Contatti e Support

Per domande o dubbi durante l'implementazione:
1. Rileggi le sezioni ANTIPATTERN vs PATTERN
2. Verifica la checklist
3. Controlla i log JSON per diagnostica
4. Consulta le risorse essenziali linkate

**Buon refactoring!** üí™